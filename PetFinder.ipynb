{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PetFinder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexvishnevskiy/PetFinder/blob/master/PetFinder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUQiaNuUEtZG"
      },
      "source": [
        "!pip install pytorch-lightning timm python-box -U albumentations wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRnRbEELKmU0",
        "outputId": "4a54142d-37d5-4f7b-ab4f-cfc538e960c8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXXLLOwO_CYY"
      },
      "source": [
        "!cp /content/drive/MyDrive/PetFinder/petfinder-pawpularity-score.zip .\n",
        "!unzip /content/petfinder-pawpularity-score.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsZBhlP6kPbv"
      },
      "source": [
        "from pytorch_lightning import LightningDataModule, LightningModule\n",
        "from pytorch_lightning.utilities.seed import seed_everything\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning import callbacks\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import albumentations as A\n",
        "\n",
        "from timm import create_model\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from box import Box\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiFd9NUd7ufm"
      },
      "source": [
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XAc3HhukPj2"
      },
      "source": [
        "cfg = {\n",
        "    'seed': 42,\n",
        "    'dir_path': '/content/',\n",
        "    'photo_path': '/content/train',\n",
        "    'csv_path': '/content/train.csv',\n",
        "    'logger': {\n",
        "        'save_dir': '/content/drive/MyDrive/PetFinder/models',\n",
        "        'name': 'bert',\n",
        "        'project': 'PetFinder',\n",
        "        'log_model': True,\n",
        "    },\n",
        "    'transform': {\n",
        "        'img_size': (224, 224),\n",
        "        'train_transforms': None,\n",
        "        'val_transforms': None,\n",
        "    },\n",
        "    'loader': {\n",
        "        'train': {\n",
        "            'batch_size': 64,\n",
        "            'num_workers': 4,\n",
        "            'shuffle': True,\n",
        "            'pin_memory': False,\n",
        "        },\n",
        "        'val': {\n",
        "            'batch_size': 64,\n",
        "            'num_workers': 4,\n",
        "            'shuffle': False,\n",
        "            'pin_memory': False,\n",
        "        }\n",
        "    },\n",
        "    'train_args': {\n",
        "        'n_splits': 5,\n",
        "        'epoch': 2,\n",
        "        'find_lr': False,\n",
        "    },\n",
        "    'model': {\n",
        "        'name': 'swin_tiny_patch4_window7_224',\n",
        "        'alias_name': 'swin_tiny',\n",
        "        'freeze_layers': 0,\n",
        "        'dropout': 0.1,\n",
        "        'output_dim': 1,\n",
        "    },\n",
        "    'loss': {\n",
        "        'module': 'nn.BCEWithLogitsLoss',\n",
        "        'alias': 'bce',\n",
        "    },\n",
        "    'optimizer':{\n",
        "        'name': 'optim.AdamW',\n",
        "        'params':{\n",
        "            'lr': 1e-5,\n",
        "            'weight_decay': 1e-4,\n",
        "        },\n",
        "    },\n",
        "    'scheduler':{\n",
        "        'name': 'optim.lr_scheduler.CosineAnnealingWarmRestarts',\n",
        "        'params':{\n",
        "            'T_0': 20,\n",
        "            'eta_min': 1e-4,\n",
        "        },\n",
        "    },\n",
        "    'trainer': {\n",
        "        'gpus': 1,\n",
        "        'accumulate_grad_batches': 1,\n",
        "        'auto_lr_find': True,\n",
        "        'progress_bar_refresh_rate': 3,\n",
        "        'fast_dev_run': False,\n",
        "        'num_sanity_val_steps': 2,\n",
        "        #'overfit_batches': 1,\n",
        "        'resume_from_checkpoint': None,\n",
        "    },\n",
        "    'results_callback': {\n",
        "        'n_images': 30,\n",
        "        'epoch': 1,\n",
        "    },\n",
        "}\n",
        "\n",
        "cfg = Box(cfg)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XbJJ11xIzVa",
        "outputId": "0bf1983d-efaa-4875-bbe8-442e298294c0"
      },
      "source": [
        "seed_everything(cfg.seed)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgM_whiFIObt"
      },
      "source": [
        "transforms = lambda img_size: A.Compose([\n",
        "     A.Resize(*img_size),\n",
        "     A.Normalize(\n",
        "         mean = [0.485, 0.456, 0.406],\n",
        "         std = [0.229, 0.224, 0.225],\n",
        "         always_apply = True\n",
        "         ),\n",
        "     ToTensorV2(),\n",
        "     ])\n",
        "\n",
        "cfg.transform.train_transforms = transforms(cfg.transform.img_size)\n",
        "cfg.transform.val_transforms = transforms(cfg.transform.img_size)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIzA0DclkPma"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, cfg, df: pd.DataFrame, stage: str):\n",
        "    super().__init__()\n",
        "    self.cfg = cfg\n",
        "    self.df = self.prepare_df(df)\n",
        "    self.stage = stage\n",
        "    if stage == 'train':\n",
        "      self.transforms = cfg.transform.train_transforms\n",
        "    else:\n",
        "      self.transforms = cfg.transform.val_transforms\n",
        "\n",
        "  def prepare_df(self, df):\n",
        "    df.loc[:, 'path'] = (\n",
        "        df['Id']\n",
        "        .apply(lambda x: os.path.join(self.cfg.photo_path, f'{x}.jpg'))\n",
        "        )\n",
        "    return df\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, index: int):\n",
        "    photo_path = self.df.iloc[index]['path']\n",
        "    label = self.df.iloc[index]['Pawpularity']\n",
        "\n",
        "    img = self.prepare_img(photo_path)\n",
        "    return img, label\n",
        "\n",
        "  def prepare_img(self, path: str):\n",
        "    _img = cv2.imread(path)\n",
        "    _img = cv2.cvtColor(_img, cv2.COLOR_BGR2RGB)\n",
        "    img = self.transforms(image=_img)['image']\n",
        "    return img"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB9mnDDCBho8"
      },
      "source": [
        "class CustomDataModule(LightningDataModule):\n",
        "  def __init__(self, cfg, train_df: pd.DataFrame, val_df: pd.DataFrame):\n",
        "    super().__init__()\n",
        "    self.cfg = cfg\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    train_split = CustomDataset(self.cfg, self.train_df, 'train')\n",
        "    return DataLoader(\n",
        "        train_split,\n",
        "        batch_size=self.cfg.loader.train.batch_size, \n",
        "        shuffle=self.cfg.loader.train.shuffle, \n",
        "        num_workers=self.cfg.loader.train.num_workers,\n",
        "        )\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    val_split = CustomDataset(self.cfg, self.val_df, 'val')\n",
        "    return DataLoader(\n",
        "        val_split, \n",
        "        batch_size=self.cfg.loader.val.batch_size, \n",
        "        shuffle=self.cfg.loader.val.shuffle,\n",
        "        num_workers=self.cfg.loader.val.num_workers,\n",
        "        )"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg2QDbsoOO8B"
      },
      "source": [
        "class CustomModel(LightningModule):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.cfg = cfg\n",
        "    self.__build_model(cfg.model.freeze_layers)\n",
        "    self._criterion = eval(self.cfg.loss.module)()\n",
        "    self.save_hyperparameters(cfg)\n",
        "    self.wandb_table = wandb.Table(columns=[\"Pawpularity\", \"pred\", \"image\"])\n",
        "\n",
        "  def __build_model(self, freeze_layers: int = 0):\n",
        "    ## add freezing of layers\n",
        "    self.backbone = create_model(\n",
        "        self.cfg.model.name, pretrained=True, num_classes=0, in_chans=3\n",
        "        )\n",
        "    num_features = self.backbone.num_features\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Dropout(self.cfg.model.dropout),\n",
        "        nn.Linear(num_features, self.cfg.model.output_dim)\n",
        "        )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    f = self.backbone(x)\n",
        "    out = self.fc(f)\n",
        "    return out\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = eval(self.cfg.optimizer.name)(\n",
        "        self.parameters(), **self.cfg.optimizer.params\n",
        "        )\n",
        "    scheduler = eval(self.cfg.scheduler.name)(\n",
        "        optimizer,\n",
        "        **self.cfg.scheduler.params\n",
        "        )\n",
        "    return [optimizer], [scheduler]\n",
        "\n",
        "  def __share_step(self, batch, stage = 'train'):\n",
        "    img, labels = batch\n",
        "    labels = labels.float()\n",
        "    logits = self(img).squeeze()\n",
        "    preds = logits.sigmoid()\n",
        "\n",
        "    cond = isinstance(self._criterion, nn.BCEWithLogitsLoss)\n",
        "    if cond:\n",
        "      labels = labels / 100.0\n",
        "      preds *= 100 \n",
        "    \n",
        "    loss = self._criterion(logits, labels)\n",
        "    labels = labels*(100**cond)\n",
        "    if stage == 'val':\n",
        "      return loss, preds, labels, img\n",
        "    return loss, preds, labels\n",
        "\n",
        "  def __share_epoch(self, outputs, stage):\n",
        "    preds = []\n",
        "    labels = []\n",
        "    for out in outputs:\n",
        "      pred, label = out['pred'], out['labels']\n",
        "      preds.append(pred)\n",
        "      labels.append(label)\n",
        "    preds = torch.cat(preds).cpu().detach()\n",
        "    labels = torch.cat(labels).cpu().detach()\n",
        "    rmse = torch.sqrt(((labels - preds) ** 2).mean())\n",
        "    self.log(f'{stage}_rmse', rmse)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    loss, preds, labels = self.__share_step(batch, 'train')\n",
        "    self.log('train_loss', loss)\n",
        "    return {'loss': loss, 'pred': preds, 'labels': labels}\n",
        "        \n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    loss, preds, labels, img = self.__share_step(batch, 'val')\n",
        "    self.log('val_loss', loss)\n",
        "\n",
        "    if batch_idx % 5 == 0:\n",
        "      for pr, l, im in zip(preds, labels, img):\n",
        "        self.wandb_table.add_data(l, pr, wandb.Image(im.squeeze()))\n",
        "\n",
        "    return {'loss': loss, 'pred': preds, 'labels': labels}\n",
        "\n",
        "  def training_epoch_end(self, outputs):\n",
        "    self.__share_epoch(outputs, 'train')\n",
        "\n",
        "  def validation_epoch_end(self, outputs):\n",
        "    self.__share_epoch(outputs, 'val')\n",
        "    wandb.log({'results': self.wandb_table})\n",
        "    self.wandb_table = wandb.Table(columns=[\"Pawpularity\", \"pred\", \"image\"])"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VigQX8Ay-dbT"
      },
      "source": [
        "skf = StratifiedKFold(n_splits=cfg.train_args.n_splits, shuffle=True, random_state=cfg.seed)\n",
        "df = pd.read_csv(cfg.csv_path)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieyLRcR1UGzB"
      },
      "source": [
        "for fold, (train_idx, val_idx) in enumerate(skf.split(df[\"Id\"], df[\"Pawpularity\"])):\n",
        "  print(f\"{'*'*100}\\n{'*'*45} fold: {fold} {'*'*46}\\n{'*'*100}\")\n",
        "\n",
        "  train_df, val_df = df.loc[train_idx], df.loc[val_idx]\n",
        "  datamodule = CustomDataModule(cfg, train_df, val_df)\n",
        "  model = CustomModel(cfg)\n",
        "\n",
        "  earystopping = EarlyStopping(monitor=\"val_loss\")\n",
        "  lr_monitor = callbacks.LearningRateMonitor()\n",
        "  loss_checkpoint = callbacks.ModelCheckpoint(\n",
        "      dirpath = cfg.logger.save_dir,\n",
        "      filename=f\"{cfg.model.alias_name}\",\n",
        "      monitor=\"val_rmse\",\n",
        "      save_top_k=1,\n",
        "      mode=\"min\",\n",
        "      save_last=False,\n",
        "      )\n",
        "\n",
        "  wandb_logger = WandbLogger(\n",
        "      name = f\"fold_{fold}\",\n",
        "      project = cfg.logger.project,\n",
        "      log_model = cfg.logger.log_model,\n",
        "      reinit = True,\n",
        "      group = f\"{cfg.logger.name}\",\n",
        "      id = f\"{cfg.model.alias_name}_fold{fold}\",\n",
        "      )\n",
        "  wandb_logger.watch(model)\n",
        "      \n",
        "  trainer = pl.Trainer(\n",
        "      max_epochs=cfg.train_args.epoch,\n",
        "      logger = wandb_logger,\n",
        "      callbacks=[lr_monitor, loss_checkpoint, earystopping],\n",
        "      deterministic=True,\n",
        "      **cfg.trainer,\n",
        "      )\n",
        "  \n",
        "  trainer.fit(model, datamodule=datamodule)\n",
        "  wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRGpq7xLnRBV"
      },
      "source": [
        "# if cfg.train_args.find_lr:\n",
        "#   lr_finder = trainer.tuner.lr_find(model, datamodule=datamodule)\n",
        "#   print(lr_finder.suggestion())\n",
        "#   fig = lr_finder.plot(suggest=True)\n",
        "#   fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixafdr7XIXTb"
      },
      "source": [
        "#cfg.optimizer.params.lr = 3e-4\n",
        "#cfg.train_args.find_lr = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ckXWpe6BThY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}